Anonymous communication significantly constrains the ability of oppressive
regimes and vigilante groups alike to suppress dissent. Newly available
information about vulnerabilities and global-scale surveillance in today's
centralized internet infrastructure has rendered a swath of anonymity tools
obsolete, and poses a significant threat to those that remain.

A trustworthy anonymity tool in the post-Snowden era must be resilient to both
surveillance and censorship: It should guarantee its users' anonymity even in
the face of a global passive adversary, and it should be unrealistic for such an
adversary to simply prevent users from accessing it. A useful anonymity tool
must also perform with reasonably low latency - a property which often trades
off with security and availability.

This review will first examine the existing anonymity tools The Onion Router
(Tor) and Dissent, considering their ability to provide strong anonymity
guarantees. Higher performance versions of both Tor and Dissent, however, rely
on well-known relay servers which present challenges for availability.
Section~\ref{Section:p2p} will examine decentralized, peer-to-peer techniques
that might be used to improve Dissent's availability.\todogrunt{Rework this
intro}

This project brings together several disparate but related areas of computer
science research. We consider work on distributed decision-making in the offline
model employed by most electronic voting research,

The major contribution of this work is to provide a protocol in which not only
are elections verifiable, but the decision to have an election and the content
of the ballots can be determined by any member at any time,
anonymously.\todo{highlight this paragraph but rewrite it because I'm
tired\ldots}

Pluralism: More than one valid opinion is possible

Networked: Adversary model is ridiculous

Decentralized: We don't trust anyone.

\section{Goals/Threat Models}
\toadd{COPY EDIT, this doesn't make sense here}
\subsection{Verifiability}
  A protocol is verifiable if its output can be
  inspected to confirm that the protocol was carried out correctly. A simple
  example of this is signing a message with the private key associated with a
  well-known public key: Anyone who knows the public key can verify the
  validity of the signature.

  % Dissent \cite{corrigan-gibbs_proactively_2013}
  % and the Neff shuffle \cite{neff_verifiable_2001} both use zero-knowledge
  % proofs to achieve verifiability.
\subsection{Anonymity}
  \paragraph{Anonymity:} A protocol guarantees anonymity in some operation a
  client can complete if the output of that operation is unlinkable (or, more
  precisely, cryptographically very difficult to link) to the client who
  completed it \cite{corrigan-gibbs_dissent:_2010}. Dissent makes use of
  pseudonyms to provide this, separating the protocol correctness and
  accountability layer from the layer in which messages are revealed. Group
  membership voting could conceivably take place at either.

\subsection{Decentralization}
  \paragraph{Accountability:} In the context of Dissent, accountability refers
  to the ability of a protocol to detect and exclude participants who disrupt
  the protocol \cite{syta_security_2014}, while proving that the disruptor did
  indeed disrupt the protocol. Such a mechanism is necessary in peer-to-peer
  protocols like Dining Cryptographers in which a single disruptor can make
  the result of a round unusable. In Dissent, accountability checks occur
  without revealing the link between any message and its sender --- moreover,
  it is not possible to deliberately exclude a participant on the basis of
  valid messages the participant sends. That is, the Dissent accountability
  mechanism does not break anonymity.
  \paragraph{Forward Progress:} A protocol that guarantees forward progress
  given certain conditions will eventually make progress as long as those
  conditions are met. More strict bounds on what ``eventually'' means are
  possible. In the original Dissent, for example, forward progress can be
  guaranteed if all clients follow the protocol and remain online, but not
  otherwise: The accountability mechanism was so arduous that $f$ disrupting
  clients could prevent any messages from being transmitted for $f$ hours
  \cite{corrigan-gibbs_proactively_2013}. Protocols that make use of quorums
  rather than being fully peer-to-peer are able to provide stronger guarantees
  of forward progress \cite{lamport_part-time_1998}.
  \subsubsection{Fault Tolerance}
  \toadd{I'm not really using any of the fault tolerance stuff; may want to
  remove this section or just talk briefly about Byzantine threat models}
    Distributed consensus protocols allow groups of nodes to come to an
    agreement on canonical values. For example, in a distributed database, if an
    unreliable power supply causes some portion of servers to be offline for
    each of several transactions, these protocols allow the
    servers to reconcile their records so that all servers agree on the
    transaction history. The problem was popularized by
    \cite{lamport_part-time_1998}, which proposed the framing and solution now
    known as Paxos: A Paxos cluster that consists of 2$f+1$ nodes must have a
    \emph{quorum} of $f + 1$ participating nodes at any given time.
    Transactions occur in three phases: First, the single current designated
    leader (Proposer) proposes the $n$th change. Next, if no other participants
    (Acceptors) have received a proposal numbered higher than $n$, the Acceptors
    promise to ignore future lower numbered requests.  Finally, upon receiving
    $f+1$ Promises, the Proposer declares success to all Acceptors. This allows
    the cluster to maintain a consistent record of transactions as long as a
    quorum is present.

  \paragraph{Byzantine Fault Tolerance}
    Paxos and many similar protocols makes the simplifying assumption that all
    nodes in the system are honest --- the only faults considered are those
    triggered by nodes suddenly going offline. If nodes may be malicious, they
    may ``fail'' not just by disappearing, but by forging messages in an effort
    to influence the consensus value. \emph{Byzantine} consensus protocols allow
    the honest nodes in a system to arrive at a canonical value, so long as some
    minimum portion of nodes are honest. The original Paxos can
    accommodate Byzantine failures if an additional verification stage, in which
    all Acceptors communicate with all other Acceptors in order to detect
    equivocation, is added before the final step \cite{castro_practical_1999}.
    Additional optimizations to regular and Byzantine Paxos have also been
    developed \cite{lamport_fast_2006}. If the adversary can not only send
    arbitrary messages but also monitor messages exchanged among other nodes,
    additional attacks are possible. One approach to this divides the nodes into
    small quorums in an effort to contain malicious nodes \cite{king_load_2011}
    while also providing better scalability than solutions that require
    all-to-all communication to thwart equivocators.

    In both its standard and Byzantine formulations, the distributed consensus
    problem assumes discrepancies in the record will only be due to faults ---
    that is, each assumes all honest participants either agree on what the value
    should be or agree to accept the value reported by the nodes who do know the
    value.  In the election of rotating leaders or servers, the correct value is
    not knowable a priori. If our leader election algorithm is modeled on other
    election protocols, it must be assumed that honest nodes may disagree on
    which servers they wish to elect.
\section{Evaluation of Existing Systems}
\subsection{Fault Tolerance}
\subsection{Electronic Voting} \label{Subsection:evoting}
  \toadd{beef up this section.}
    Secure electronic voting systems have arisen largely out of a desire to
    retain secret ballots (no one should learn how a particular voter voted)
    while also guaranteeing accurate and fair counting of votes. Unlike
    distributed consensus protocols, secure electronic voting systems generally
    achieve their security properties through decentralization of trust rather
    than computation. They normally depend on a single executor of the vote
    aggregation protocol, using verifiability to ensure that each voter can be
    confident their vote was tallied fairly. Voting protocols can be evaluated
    in their provision of three different kinds of verifiability
    \cite{kremer_election_2010}: \emph{individual} verifiability ensures that a
    voter can verify their vote was included correctly. \emph{Universal}
    verifiability requires that anybody can verify the election result correctly
    represents the collection of ballots cast. Finally, \emph{Eligibility}
    verifiability allows anybody to verify that only eligible voters voted, and
    that each voter voted only once.

    One solution is presented in \cite{neff_verifiable_2001},
    and the initial assignment of pseudonyms in Dissent already uses a variation
    on this protocol. In the Neff shuffle, each voter encrypts their vote in
    such a way that the aggregator must permute the vote ciphertexts before
    being able to decrypt them. The result is a permutation which no one knows
    --- a voter can verify that their ciphertext is present in the permutation,
    but gains no information about the correspondence between other ciphertexts
    and other voters. It is both individually and universally verifiable.

    The individual verifiability of \cite{neff_verifiable_2001} is based on each
    voter's retention of their secret key. \emph{Coercion-resistant} electronic
    voting protocols remain robust even if secret keys are compromised: In
    \cite{juels_coercion-resistant_2005}, the voter uses their secret key only
    to establish eligibility, at which point they are assigned a random element
    of a well known set to use in their actual ballot. The ballots are
    unlinkable to the secret keys, and there is no way for an outsider to
    confirm whether a particular random element corresponds with a particular
    voter. This protocol achieves strong resistance to multiple kinds of
    coercion by deliberately weakening the eligibility verification property to
    depend on trust in the ``registrar'' who validates credentials and assigns the
    voting keys, preventing ``forced-abstention'' attacks (in which the adversary
    demands a voter simply not participate) by making it impossible for
    outsiders to verify the set of voters.

    These protocols provide useful templates for how a distributed voting
    protocol might accomplish similar security properties.

\subsection{Anonymity Protocols}
\label{subsection:ExistingAnonymity}
\toadd{Set this up as problems with electronic voting schemes}
  Every anonymity tool shares one basic goal: Given a set of assumptions about
  an adversary's capabilities, an anonymity tool provides a way for a user to
  broadcast a message without the adversary being able to discover the author of
  the message.
  To illustrate the general approach and some common security assumptions, we
  first consider The Onion Router (Tor), the most widely used anonymity tool
  today\cite{ford_hiding_2014}

  \subsection{Onion Routing with Tor}
  \label{Subsubsection:Tor}
  \toadd{this section is probably not needed}
    Tor aims to provide an anonymity service that, to the end user, behaves like
    a one-hop proxy: If Alicia wants to send an HTTP request to Badru using Tor,
    Alicia sends a request through Tor, Tor forwards the request to Badru, Badru
    replies to Tor, and Tor forwards the response to Alice. Under the surface,
    when Alicia's traffic enters the Tor network, it is encrypted and
    transmitted among several "onion routers" before reaching an "exit relay",
    which decrypts the request and passes it onto Badru. Each intermediate onion
    router only knows the next hop in the path from Alicia to Badru - no single
    node knows its traffic originated at Alicia or is en route to Badru - so no
    one in the network knows the complete path.

    Tor provides anonymity from an adversary who ``can observe some fraction of
    the network traffic; who can generate, modify, delete, or delay traffic; who
    can operate onion routers of [their] own; and who can compromise some
    fraction of the onion routers''\cite{dingledine_tor:_2004}. If an adversary
    can observe much more than a small fraction of traffic, or if the adversary
    controls many colluding nodes, other attacks become possible, and the
    anonymity guarantees no longer hold. We now know that the U.S. National
    Security Agency actively uses such attacks, and so a new protocol is
    necessary in order to remain anonymous from the N.S.A.

  \subsection{New Threat Models}
  \label{Subsubsection:NewThreats} To
    provide anonymity from an adversary like the N.S.A., a modern anonymity
    protocol must protect against several forms of attacks. Feigenbaum et.
    al.\cite{feigenbaum_seeking_2013} highlight five specific attacks to which
    onion routing is vulnerable:
    \paragraph{Global traffic analysis:} If the
    adversary can monitor most of the traffic on the internet globally, the
    adversary can with high probability see the link from Alicia to the Tor
    network and from the Tor exit relay to Badru. This means the adversary can
    observe that the messages Alicia sends correspond to messages Badru receives
    some short amount of time later. Even if the messages themselves are
    encrypted, the adversary can analyze the lengths and other metadata about
    the messages to correlate this traffic.
    \paragraph{Active attacks:}
    Global traffic analysis attacks only require the adversary to be able to
    monitor global traffic. If the adversary can also modify or generate
    traffic, several other attacks are possible. The adversary can launch
    \emph{man-in-the-middle} (MITM) attacks in which it impersonates Alicia,
    Badru, or one or more Tor nodes. The adversary can launch \emph{Sybil}
    attacks, in which many different Tor clients controlled by the same
    adversary join the network as individual clients. Either of these can be
    used to create \emph{Denial-of-Service} (DoS) attacks, which might either
    prevent users from connecting to Tor at all, or force Tor traffic to go
    through particular, potentially adversary-controlled, Tor nodes ---
    de-anonymizing the users.
    \paragraph{Intersection attacks:} In general,
    it is possible to tell when users are using an anonymity service --- the
    anonymity comes from the difficulty of linking any particular user to
    particular messages produced by the service. Over time, however, the client
    set of an anonymity service is unlikely to remain fixed. A passive
    adversary monitoring the outputs of an anonymity service as well as
    the set of users connected can narrow the set of users who
    potentially, for example, updated a particular blog with a static
    pseudonym, by excluding users  not online during all updates to the
    blog.
    \toadd{conclusion}

  \subsubsection{The Trouble with Relays}
  \label{Subsection:Relays}
  \todoword{copy edit Tor vs. Dissent}
    One potential approach to making Dissent widely available would be to have
    well-known, globally dispersed Dissent servers available for clients to
    connect to, similar to the current state of Tor. Any such well-known server
    list, however, is susceptible to blocking by internet service providers. It
    would therefore be preferable to have servers be short-lived, or at least
    not well known. Since Dissent takes place over regular TCP connections,
    detecting that the protocol is being executed without knowledge of the
    addresses of servers would be difficult to accomplish without a great number
    of false positives \cite{houmansadr_parrot_2013}, so this may be enough to
    realistically preclude most attempts to block access to the protocol
    entirely.  Additionally, while the current version of Dissent guarantees
    that malicious servers cannot deanonymize a client without the cooperation
    of all servers, and guarantees that disrupting servers can be exposed, it
    provides no way to remove a disrupting or malicious server form the system.

    One way to resolve these problems would be to have clusters of Dissent
    clients elect temporary servers among themselves, allowing servers to either
    step down (e.g., by going offline) or be impeached by some portion of the
    clients.  Doing so in a truly decentralized and fair fashion is a
    non-trivial problem.  We consider several other areas of research relevant
    to solving it.

\section{Conclusion}\todoword{better name}
% \begin{tabular}{p{2.5cm}p{2cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}
%   \cline{3-12}
%   & & \multicolumn{3}{c|}{Voting Protocols}     &
%                               \multicolumn{3}{|c|}{Consensus Protocols} &
%                                                           \multicolumn{3}{|c|}{Anonymity Protocols} & This Protocol\\
%   \cline{3-12}
%   & &                     Neff & Kremer & Juels & Paxos & Byzantine
%                                                           Paxos & King & Tor & Dissent & Dissent
%                                                                                          in
%                                                                                          Numbers    &   \\
%   \cline{1-12}
%   \multicolumn{1}{|p{2.5cm}}{\multirow{2}{*}{Verifiability} } &
%   \multicolumn{1}{|p{2cm}|}{Individual}        & yes &      &      & no & no?    &        & n/a & yes? & & \\ \cline{2-12}
%   \multicolumn{1}{|c}{} &
%   \multicolumn{1}{|p{2cm}|}{Universal}         & yes &      &      & no & no?    &        & n/a & yes? & & \\ \cline{1-12}
%   \multicolumn{1}{|p{2.5cm}}{\multirow{2}{*}{Anonymity} } &
%   \multicolumn{1}{|p{2cm}|}{Secret Ballots}    & yes &      &      & no & no?    &        & n/a & yes? & & \\ \cline{2-12}
%   \multicolumn{1}{|c}{} &
%   \multicolumn{1}{|p{2cm}|}{Secret Initiators} & yes &      &      & no & no?    &        & n/a & yes? & & \\ \cline{1-12}
%   \multicolumn{1}{|p{2.5cm}}{\multirow{2}{*}{Decentralized Trust/Netowrk} }&
%   \multicolumn{1}{|p{2cm}|}{Byzantine}         & yes  &     &      & no & no?    &        & n/a & yes? & & \\ \cline{2-12}
%   \multicolumn{1}{|c}{} &
%   \multicolumn{1}{|p{2cm}|}{Global Passive}    & yes  &     &      & no & no?    &        & n/a & yes? & & \\ \cline{1-12}
% \end{tabular}

\begin{table}
\begin{center}
\begin{tabularx}{0.75\paperwidth}{XX|X|X|X|X|X|X|}
  \cline{3-8}
  & & \multicolumn{2}{X|}{Verifiability} & \multicolumn{2}{|X|}{Anonymity} &
  \multicolumn{2}{|X|}{Decentralized Trust/Network} \\ \cline{3-8}
& & Individual & Universal & Secret Ballots & Secret Initiators & Byzantine &
Global Passive \\
\cline{1-8}
\multicolumn{1}{|X}{\multirow{3}{*}{Voting Protocols} } &
\multicolumn{1}{|X|}{Neff} & & & & &\\ \cline{2-8}
\multicolumn{1}{|X}{} &
\multicolumn{1}{|X|}{Kremer} & & & & &\\ \cline{2-8}
\multicolumn{1}{|X}{} &
\multicolumn{1}{|X|}{Juels} & & & & &\\ \cline{1-8}
\multicolumn{1}{|X}{\multirow{3}{*}{Consensus Protocols} } &
\multicolumn{1}{|X|}{Neff} & & & & &\\ \cline{2-8}
\multicolumn{1}{|X}{} &
\multicolumn{1}{|X|}{Kremer} & & & & &\\ \cline{2-8}
\multicolumn{1}{|X}{} &
\multicolumn{1}{|X|}{Juels} & & & & &\\ \cline{1-8}
\multicolumn{1}{|X}{\multirow{3}{*}{Anonymity Protocols} } &
\multicolumn{1}{|X|}{Neff} & & & & &\\ \cline{2-8}
\multicolumn{1}{|X}{} &
\multicolumn{1}{|X|}{Kremer} & & & & &\\ \cline{2-8}
\multicolumn{1}{|X}{} &
\multicolumn{1}{|X|}{Juels} & & & & &\\ \cline{1-8}
\multicolumn{1}{|X}{This Protocol} & & & & & & \\ \cline{1-8}
% \multicolumn{1}{|p{2cm}}{\multirow{3}{*}{This Protocol} } &
% \multicolumn{1}{|p{2cm}}{} &
% \multicolumn{1}{|p{2cm}}{} &
% \multicolumn{1}{|p{2cm}}{} \\ \cline{1-8}
\end{tabularx}
\end{center}
\end{table}
