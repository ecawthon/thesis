Anonymous communication significantly constrains the ability of oppressive
regimes and vigilante groups alike to suppress dissent. Newly available
information about vulnerabilities and global-scale surveillance in today's
centralized internet infrastructure has rendered a swath of anonymity tools
obsolete, and poses a significant threat to those that remain.

A trustworthy anonymity tool in the post-Snowden era must be resilient to both
surveillance and censorship: It should guarantee its users' anonymity even in
the face of a global passive adversary, and it should be unrealistic for such an
adversary to simply prevent users from accessing it. A useful anonymity tool
must also perform with reasonably low latency - a property which often trades
off with security and availability.

This review will first examine the existing anonymity tools The Onion Router
(Tor) and Dissent, considering their ability to provide strong anonymity
guarantees. Higher performance versions of both Tor and Dissent, however, rely
on well-known relay servers which present challenges for availability.
Section~\ref{Section:p2p} will examine decentralized, peer-to-peer techniques
that might be used to improve Dissent's availability.

\section{Anonymity Designs and Threat Models}
\label{Section:ExistingAnonymity}
  Every anonymity tool shares one basic goal: Given a set of assumptions about
  an adversary's capabilities, an anonymity tool provides a way for a user to
  broadcast a message without the adversary being able to discover the author of
  the message.
  To illustrate the general approach and some common security assumptions, we
  first consider The Onion Router (Tor), the most widely used anonymity tool
  today\cite{ford_hiding_2014}

  \subsection{Onion Routing with Tor}
  \label{Subsection:Tor}
    Tor aims to provide an anonymity service that, to the end user, behaves like
    a one-hop proxy: If Alicia wants to send an HTTP request to Badru using Tor,
    Alicia sends a request through Tor, Tor forwards the request to Badru, Badru
    replies to Tor, and Tor forwards the response to Alice. Under the surface,
    when Alicia's traffic enters the Tor network, it is encrypted and
    transmitted among several "onion routers" before reaching an "exit relay",
    which decrypts the request and passes it onto Badru. Each intermediate onion
    router only knows the next hop in the path from Alicia to Badru - no single
    node knows its traffic originated at Alicia or is en route to Badru - so no
    one in the network knows the complete path.

    Tor provides anonymity from an adversary who ``can observe some fraction of
    the network traffic; who can generate, modify, delete, or delay traffic; who
    can operate onion routers of [their] own; and who can compromise some
    fraction of the onion routers''\cite{dingledine_tor:_2004}. If an adversary
    can observe much more than a small fraction of traffic, or if the adversary
    controls many colluding nodes, other attacks become possible, and the
    anonymity guarantees no longer hold. We now know that the U.S. National
    Security Agency actively uses such attacks, and so a new protocol is
    necessary in order to remain anonymous from the N.S.A.

  \subsection{New Threat Models}
  \label{Subsection:NewThreats} To
    provide anonymity from an adversary like the N.S.A., a modern anonymity
    protocol must protect against several forms of attacks. Feigenbaum et.
    al.\cite{feigenbaum_seeking_2013} highlight five specific attacks to which
    onion routing is vulnerable:
    \subparagraph{Global traffic analysis:} If the
    adversary can monitor most of the traffic on the internet globally, the
    adversary can with high probability see the link from Alicia to the Tor
    network and from the Tor exit relay to Badru. This means the adversary can
    observe that the messages Alicia sends correspond to messages Badru receives
    some short amount of time later. Even if the messages themselves are
    encrypted, the adversary can analyze the lengths and other metadata about
    the messages to correlate this traffic.
    \subparagraph{Active attacks:}
    Global traffic analysis attacks only require the adversary to be able to
    monitor global traffic. If the adversary can also modify or generate
    traffic, several other attacks are possible. The adversary can launch
    \emph{man-in-the-middle} (MITM) attacks in which it impersonates Alicia,
    Badru, or one or more Tor nodes. The adversary can launch \emph{Sybil}
    attacks, in which many different Tor clients controlled by the same
    adversary join the network as individual clients. Either of these can be
    used to create \emph{Denial-of-Service} (DoS) attacks, which might either
    prevent users from connecting to Tor at all, or force Tor traffic to go
    through particular, potentially adversary-controlled, Tor nodes ---
    de-anonymizing the users.
    `\subparagraph{Intersection attacks:} In general,
    it is possible to tell when users are using an anonymity service --- the
    anonymity comes from the difficulty of linking any particular user to
    particular messages produced by the service. Over time, however, the client
    set of an anonymity service is unlikely to remain fixed. A passive
    adversary monitoring the outputs of an anonymity service as well as
    the set of users connected can narrow the set of users who
    potentially, for example, updated a particular blog with a static
    pseudonym, by excluding users  not online during all updates to the
    blog.

    We now turn to an anonymity service designed to be resilient to these threat
    models.

  \subsection{Dissent}
  \label{Subsection:Dissent}
    Dissent is an alternative to Tor that provides provable anonymity even if
    only one server in the network is honest\cite{corrigan-gibbs_dissent:_2010}.
    In its present form, a Dissent cluster consists of $m$ servers and $n$
    connected clients\cite{wolinsky_dissent_2012}. Provable anonymity is
    achieved through a modified version of the Dining Cryptographers
    problem\cite{chaum_dining_1988}: each client $i$ shares a secret $K_{ij}$
    with each server $j$. Communication proceeds in rounds, within which each
    client has a designated $k$-bit slot.  Before any messages are sent, a
    secure shuffle\cite{neff_verifiable_2001} assigns each client to a slot so
    that the owner of a slot is the only node in the system which knows who owns
    that slot.  In any client $s$'s slot, every client and every server
    generates $k$ bits of random noise seeded with each of its shared secrets
    $K_{ij}$, and combines these with an exclusive or (xor) operation to produce
    that node's ciphertext. Client $s$ also combines (via xor) a $k$-bit message
    with its noise to create its ciphertext. The combination (via xor) of all
    clients' and servers' ciphertext includes the noise stream associated with
    each shared secret twice, and so all noise cancels out and client $s$'
    message is revealed. However, since deciphering this requires the
    participation of all nodes in the system, it is impossible to tell which
    client transmitted a message in a given slot. Dissent also incorporates an
    accountability mechanism, allowing any node that disrupts the protocol to be
    detected and removed from the cluster
    \cite{corrigan-gibbs_proactively_2013}.

    The original Dissent was fully peer-to-peer
    \cite{corrigan-gibbs_dissent:_2010}. The shift to a client-server model
    allows for significantly improved performance, but it introduces several new
    concerns, particularly relating to misbehaving servers, a new class of DoS
    attacks, and group formation.

  \subsection{The Trouble with Relays}
  \label{Subsection:Relays}
    One potential approach to making Dissent widely available would be to have
    well-known, globally dispersed Dissent servers available for clients to
    connect to, similar to the current state of Tor. Any such well-known server
    list, however, is susceptible to blocking by internet service providers. It
    would therefore be preferable to have servers be short-lived, or at least
    not well known. Since Dissent takes place over regular TCP connections,
    detecting that the protocol is being executed without knowledge of the
    addresses of servers would be difficult to accomplish without a great number
    of false positives \cite{houmansadr_parrot_2013}, so this may be enough to
    realistically preclude most attempts to block access to the protocol
    entirely.  Additionally, while the current version of Dissent guarantees
    that malicious servers cannot deanonymize a client without the cooperation
    of all servers, and guarantees that disrupting servers can be exposed, it
    provides no way to remove a disrupting or malicious server form the system.

    One way to resolve these problems would be to have clusters of Dissent
    clients elect temporary servers among themselves, allowing servers to either
    step down (e.g., by going offline) or be impeached by some portion of the
    clients.  Doing so in a truly decentralized and fair fashion is a
    non-trivial problem.  We consider several other areas of research relevant
    to solving it.

\section{Distributed Decision-Making}
\label{Section:p2p}
  In a peer-to-peer Dissent protocol that does not specify leaders or servers
  prior to starting, there must be some way for participants to collectively
  decide on features of the cluster, such as which nodes will act as servers. In
  this section, we examine various existing approaches to distributed
  decision-making problems. We first consider several potential design goals,
  and then discuss particular approaches to these problems.

  \subsection{Potential Goals}
    \paragraph{Verifiability:} A protocol is verifiable if its output can be
    inspected to confirm that the protocol was carried out correctly. A simple
    example of this is signing a message with the private key associated with a
    well-known public key: Anyone who knows the public key can verify the
    validity of the signature. Dissent \cite{corrigan-gibbs_proactively_2013}
    and the Neff shuffle \cite{neff_verifiable_2001} both use zero-knowledge
    proofs to achieve verifiability.
    \paragraph{Accountability:} In the context of Dissent, accountability refers
    to the ability of a protocol to detect and exclude participants who disrupt
    the protocol \cite{syta_security_2014}, while proving that the disruptor did
    indeed disrupt the protocol. Such a mechanism is necessary in peer-to-peer
    protocols like Dining Cryptographers in which a single disruptor can make
    the result of a round unusable. In Dissent, accountability checks occur
    without revealing the link between any message and its sender --- moreover,
    it is not possible to deliberately exclude a participant on the basis of
    valid messages the participant sends. That is, the Dissent accountability
    mechanism does not break anonymity.
    \paragraph{Forward Progress:} A protocol that guarantees forward progress
    given certain conditions will eventually make progress as long as those
    conditions are met. More strict bounds on what ``eventually'' means are
    possible. In the original Dissent, for example, forward progress can be
    guaranteed if all clients follow the protocol and remain online, but not
    otherwise: The accountability mechanism was so arduous that $f$ disrupting
    clients could prevent any messages from being transmitted for $f$ hours
    \cite{corrigan-gibbs_proactively_2013}. Protocols that make use of quorums
    rather than being fully peer-to-peer are able to provide stronger guarantees
    of forward progress \cite{lamport_part-time_1998}.
    \paragraph{Anonymity:} A protocol guarantees anonymity in some operation a
    client can complete if the output of that operation is unlinkable (or, more
    precisely, cryptographically very difficult to link) to the client who
    completed it \cite{corrigan-gibbs_dissent:_2010}. Dissent makes use of
    pseudonyms to provide this, separating the protocol correctness and
    accountability layer from the layer in which messages are revealed. Group
    membership voting could conceivably take place at either.

  \subsection{Consensus Protocols}
    Distributed consensus protocols allow groups of nodes to come to an
    agreement on canonical values. For example, in a distributed database, if an
    unreliable power supply causes some portion of servers to be offline for
    each of several transactions, these protocols allow the
    servers to reconcile their records so that all servers agree on the
    transaction history. The problem was popularized by
    \cite{lamport_part-time_1998}, which proposed the framing and solution now
    known as Paxos: A Paxos cluster that consists of 2$f+1$ nodes must have a
    \emph{quorum} of $f + 1$ participating nodes at any given time.
    Transactions occur in three phases: First, the single current designated
    leader (Proposer) proposes the $n$th change. Next, if no other participants
    (Acceptors) have received a proposal numbered higher than $n$, the Acceptors
    promise to ignore future lower numbered requests.  Finally, upon receiving
    $f+1$ Promises, the Proposer declares success to all Acceptors. This allows
    the cluster to maintain a consistent record of transactions as long as a
    quorum is present.

    Paxos and many similar protocols makes the simplifying assumption that all
    nodes in the system are honest --- the only faults considered are those
    triggered by nodes suddenly going offline. If nodes may be malicious, they
    may ``fail'' not just by disappearing, but by forging messages in an effort
    to influence the consensus value. \emph{Byzantine} consensus protocols allow
    the honest nodes in a system to arrive at a canonical value, so long as some
    minimum portion of nodes are honest. The original Paxos can
    accommodate Byzantine failures if an additional verification stage, in which
    all Acceptors communicate with all other Acceptors in order to detect
    equivocation, is added before the final step \cite{castro_practical_1999}.
    Additional optimizations to regular and Byzantine Paxos have also been
    developed \cite{lamport_fast_2006}. If the adversary can not only send
    arbitrary messages but also monitor messages exchanged among other nodes,
    additional attacks are possible. One approach to this divides the nodes into
    small quorums in an effort to contain malicious nodes \cite{king_load_2011}
    while also providing better scalability than solutions that require
    all-to-all communication to thwart equivocators.

    In both its standard and Byzantine formulations, the distributed consensus
    problem assumes discrepancies in the record will only be due to faults ---
    that is, each assumes all honest participants either agree on what the value
    should be or agree to accept the value reported by the nodes who do know the
    value.  In the election of rotating leaders or servers, the correct value is
    not knowable a priori. If our leader election algorithm is modeled on other
    election protocols, it must be assumed that honest nodes may disagree on
    which servers they wish to elect.

  \subsection{Electronic Voting}
    Secure electronic voting systems have arisen largely out of a desire to
    retain secret ballots (no one should learn how a particular voter voted)
    while also guaranteeing accurate and fair counting of votes. Unlike
    distributed consensus protocols, secure electronic voting systems generally
    achieve their security properties through decentralization of trust rather
    than computation. They normally depend on a single executor of the vote
    aggregation protocol, using verifiability to ensure that each voter can be
    confident their vote was tallied fairly. Voting protocols can be evaluated
    in their provision of three different kinds of verifiability
    \cite{kremer_election_2010}: \emph{individual} verifiability ensures that a
    voter can verify their vote was included correctly. \emph{Universal}
    verifiability requires that anybody can verify the election result correctly
    represents the collection of ballots cast. Finally, \emph{Eligibility}
    verifiability allows anybody to verify that only eligible voters voted, and
    that each voter voted only once.

    One solution is presented in \cite{neff_verifiable_2001},
    and the initial assignment of pseudonyms in Dissent already uses a variation
    on this protocol. In the Neff shuffle, each voter encrypts their vote in
    such a way that the aggregator must permute the vote ciphertexts before
    being able to decrypt them. The result is a permutation which no one knows
    --- a voter can verify that their ciphertext is present in the permutation,
    but gains no information about the correspondence between other ciphertexts
    and other voters. It is both individually and universally verifiable.

    The individual verifiability of \cite{neff_verifiable_2001} is based on each
    voter's retention of their secret key. \emph{Coercion-resistant} electronic
    voting protocols remain robust even if secret keys are compromised: In
    \cite{juels_coercion-resistant_2005}, the voter uses their secret key only
    to establish eligibility, at which point they are assigned a random element
    of a well known set to use in their actual ballot. The ballots are
    unlinkable to the secret keys, and there is no way for an outsider to
    confirm whether a particular random element corresponds with a particular
    voter. This protocol achieves strong resistance to multiple kinds of
    coercion by deliberately weakening the eligibility verification property to
    depend on trust in the ``registrar'' who validates credentials and assigns the
    voting keys, preventing ``forced-abstention'' attacks (in which the adversary
    demands a voter simply not participate) by making it impossible for
    outsiders to verify the set of voters.

    These protocols provide useful templates for how a distributed voting
    protocol might accomplish similar security properties.

