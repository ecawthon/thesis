% Anonymous communication significantly constrains the ability of oppressive
% regimes and vigilante groups alike to suppress dissent. Newly available
% information about vulnerabilities and global-scale surveillance in today's
% centralized internet infrastructure has rendered a swath of anonymity tools
% obsolete, and poses a significant threat to those that remain.
%
% A trustworthy anonymity tool in the post-Snowden era must be resilient to both
% surveillance and censorship: It should guarantee its users' anonymity even in
% the face of a global passive adversary, and it should be unrealistic for such an
% adversary to simply prevent users from accessing it. A useful anonymity tool
% must also perform with reasonably low latency - a property which often trades
% off with security and availability.
%
% This review will first examine the existing anonymity tools The Onion Router
% (Tor) and Dissent, considering their ability to provide strong anonymity
% guarantees. Higher performance versions of both Tor and Dissent, however, rely
% on well-known relay servers which present challenges for availability.
% Section~\ref{Section:p2p} will examine decentralized, peer-to-peer techniques
% that might be used to improve Dissent's availability.\todogrunt{Rework this
% intro}
%
This project brings together several disparate but related areas of computer
science research.  Three existing bodies of work are particularly useful here:
For verifiability, we turn to offline electronic voting protocols (which
centralize computation but not trust). For decentralization, we look to work on
fault tolerance and distributed consensus.\todo{Idea: centralization of truth?}
Finally, we review existing work on anonymous group communication.
\todoword{Make sure this order matches the order in \ref{Chapter:Goals}}
\section{Electronic Voting} \label{Section:evoting}
    Secure electronic voting systems have arisen largely out of a desire to
    retain secret ballots (no one should learn how a particular voter voted)
    while also guaranteeing accurate and fair counting of votes. Unlike
    distributed consensus protocols, secure electronic voting systems generally
    achieve their security properties through decentralization of trust rather
    than computation. They normally depend on a single executor of the vote
    aggregation protocol, using verifiability to ensure that each voter can be
    confident their vote was tallied fairly.

    One solution is presented in \cite{neff}, and the initial assignment of
    pseudonyms in Dissent already uses a variation on this protocol. In the Neff
    shuffle, each voter encrypts their vote in such a way that the aggregator
    must permute the vote ciphertexts before being able to decrypt them. The
    result is a permutation which no one knows --- a voter can verify that their
    ciphertext is present in the permutation, but gains no information about the
    correspondence between other ciphertexts and other voters. It is both
    individually and universally verifiable.

    The individual verifiability of \cite{neff} is based on each
    voter's retention of their secret key. \emph{Coercion-resistant} electronic
    voting protocols remain robust even if secret keys are compromised: In
    \cite{juels_coercion-resistant_2005}, the voter uses their secret key only
    to establish eligibility, at which point they are assigned a random element
    of a well known set to use in their actual ballot. The ballots are
    unlinkable to the secret keys, and there is no way for an outsider to
    confirm whether a particular random element corresponds with a particular
    voter. This protocol achieves strong resistance to multiple kinds of
    coercion by deliberately weakening the eligibility verification property to
    depend on trust in the ``registrar'' who validates credentials and assigns
    the voting keys, preventing ``forced-abstention'' attacks (in which the
    adversary demands a voter simply not participate) by making it impossible
    for outsiders to verify the set of voters.

    These protocols provide useful templates for how a distributed voting
    protocol might accomplish similar security properties.

  \section{Byzantine Fault Tolerance}
    In shifting our focus from offline voting algorithms to networked protocols,
    we must consider several types of disruptions not taken into account by
    those algorithms. In particular, any member tasked with ``broadcasting'' a
    message may equivocate, sending different values to different participants.
    Existing work on distributed consensus provides various approaches to these
    problems.

    Distributed consensus protocols allow groups of nodes to come to an
    agreement on canonical values. For example, in a distributed database, if an
    unreliable power supply causes some portion of servers to be offline for
    each of several transactions, these protocols allow the
    servers to reconcile their records so that all servers agree on the
    transaction history. The problem was popularized by
    \cite{paxos}, which proposed the framing and solution now
    known as Paxos: A Paxos cluster that consists of 2$f+1$ nodes must have a
    \emph{quorum} of $f + 1$ participating nodes at any given time.
    Transactions occur in three phases: First, the single current designated
    leader (Proposer) proposes the $n$th change. Next, if no other participants
    (Acceptors) have received a proposal numbered higher than $n$, the Acceptors
    promise to ignore future lower numbered requests.  Finally, upon receiving
    $f+1$ Promises, the Proposer declares success to all Acceptors. This allows
    the cluster to maintain a consistent record of transactions as long as a
    quorum is present.

    Paxos and many similar protocols makes the simplifying assumption that all
    nodes in the system are honest --- the only faults considered are those
    triggered by nodes suddenly going offline. If nodes may be malicious, they
    may ``fail'' not just by disappearing, but by forging messages in an effort
    to influence the consensus value. \emph{Byzantine} consensus protocols allow
    the honest nodes in a system to arrive at a canonical value, so long as some
    minimum portion of nodes are honest. The original Paxos can
    accommodate Byzantine failures if an additional verification stage, in which
    all Acceptors communicate with all other Acceptors in order to detect
    equivocation, is added before the final step \cite{castro_practical_1999}.
    Additional optimizations to regular and Byzantine Paxos have also been
    developed \cite{lamport_fast_2006}. If the adversary can not only send
    arbitrary messages but also monitor messages exchanged among other nodes,
    additional attacks are possible. One approach to this divides the nodes into
    small quorums in an effort to contain malicious nodes \cite{king_load_2011}
    while also providing better scalability than solutions that require
    all-to-all communication to thwart equivocators.

    In both its standard and Byzantine formulations, the distributed consensus
    problem assumes discrepancies in the record will only be due to faults ---
    that is, each assumes all honest participants either agree on what the value
    should be or agree to accept the value reported by the nodes who do know the
    value.  In the election of rotating leaders or servers, the correct value is
    not knowable a priori. If our leader election algorithm is modeled on other
    election protocols, it must be assumed that honest nodes may disagree on
    which servers they wish to elect.

\section{Anonymity Protocols}
\label{subsection:ExistingAnonymity}
  Every anonymity tool shares one basic goal: Given a set of assumptions about
  an adversary's capabilities, an anonymity tool provides a way for a user to
  transmit a message without the adversary being able to discover the author
  of the message.  To illustrate the general approach and some common
  security assumptions, we first consider The Onion Router (Tor), the most
  widely used anonymity tool today\cite{ford_hiding_2014}

  \subsection{Onion Routing with Tor}
    Tor aims to provide an anonymity service that, to the end user, behaves like
    a one-hop proxy: If Alicia wants to send an HTTP request to Badru using Tor,
    Alicia sends a request through Tor, Tor forwards the request to Badru, Badru
    replies to Tor, and Tor forwards the response to Alice. Under the surface,
    when Alicia's traffic enters the Tor network, it is encrypted and
    transmitted among several "onion routers" before reaching an "exit relay",
    which decrypts the request and passes it onto Badru. Each intermediate onion
    router only knows the next hop in the path from Alicia to Badru - no single
    node knows its traffic originated at Alicia or is en route to Badru - so no
    one in the network knows the complete path.

    Tor provides anonymity from an adversary who ``can observe some fraction of
    the network traffic; who can generate, modify, delete, or delay traffic; who
    can operate onion routers of [their] own; and who can compromise some
    fraction of the onion routers''\cite{dingledine_tor:_2004}. If an adversary
    can observe much more than a small fraction of traffic, or if the adversary
    controls many colluding nodes, other attacks become possible, and the
    anonymity guarantees no longer hold. We now know that the U.S. National
    Security Agency actively uses such attacks, and so a new protocol is
    necessary in order to remain anonymous from the N.S.A.

  \subsection{Strong Anonymity with Dissent}
    Dissent is an alternative to Tor that provides provable anonymity for $k$
    honest users even if every other node in the network is dishonest
    \cite{p2pd}.  Provable anonymity is achieved through a modified version of
    the Dining Cryptographers problem\cite{chaum_dining_1988}: each node $i$
    shares a secret $K_{ij}$ with each other node $j$. Communication proceeds in
    rounds, within which each node has a designated $b$-bit slot.  Before any
    messages are sent, a secure shuffle\cite{neff} assigns each node to a slot
    so that the owner of a slot is the only node in the system which knows who
    owns that slot.  In any node $s$'s slot, every node generates $b$ bits of
    random noise seeded with each of its shared secrets $K_{ij}$, and combines
    these with an exclusive or (xor) operation to produce that node's
    ciphertext. Node $s$ also combines (via xor) a $b$-bit message with its
    noise to create its ciphertext. The combination (via xor) of all nodes'
    ciphertext includes the noise stream associated with each shared secret
    twice, and so all noise cancels out and node $s$'s message is revealed.
    However, since deciphering this requires the participation of all nodes in
    the system, it is impossible to tell which client transmitted a message in a
    given slot. Dissent also incorporates an accountability mechanism, allowing
    any node that disrupts the protocol to be detected and removed from the
    cluster \cite{verdict}.

\section{New Threat Models}
Newly available information about vulnerabilities and global-scale
surveillance in today's centralized internet infrastructure has brought new
security considerations and threat models to the foreground of networked
system research. It has rendered a swath of anonymity and voting tools
obsolete, and poses a significant threat to those that remain. Group
management protocols aimed at dissidents must take this into account.

To provide anonymity from an adversary like the N.S.A., a modern anonymity
protocol must protect against several forms of attacks. Feigenbaum et.
al.\cite{feigenbaum_seeking_2013} highlight several specific attacks to
which onion routing is vulnerable:
\paragraph{Global traffic analysis:}
If the adversary can monitor most of the traffic on the internet globally,
the adversary can with high probability see the link from Alicia to the Tor
network and from the Tor exit relay to Badru. This means the adversary can
observe that the messages Alicia sends correspond to messages Badru receives
some short amount of time later. Even if the messages themselves are
encrypted, the adversary can analyze the lengths and other metadata about
the messages to correlate this traffic.
\paragraph{Intersection attacks:}
In general, it is possible to tell when users are using an anonymity service
--- the anonymity comes from the difficulty of linking any particular user
to particular messages produced by the service. Over time, however, the
client set of an anonymity service is unlikely to remain fixed. A passive
adversary monitoring the outputs of an anonymity service as well as the set
of users connected can narrow the set of users who potentially, for example,
updated a particular blog with a static pseudonym, by excluding users  not
online during all updates to the blog.
\paragraph{Active attacks:}
Global traffic analysis attacks only require the adversary to be able to
monitor global traffic. If the adversary can also modify or generate
traffic, several other attacks are possible. The adversary can launch
\emph{man-in-the-middle} (MITM) attacks in which it impersonates Alicia,
Badru, or one or more Tor nodes. The adversary can launch \emph{Sybil}
attacks, in which many different Tor clients controlled by the same
adversary join the network as individual clients. Either of these can be
used to create \emph{Denial-of-Service} (DoS) attacks, which might either
prevent users from connecting to Tor at all, or force Tor traffic to go
through particular, potentially adversary-controlled, Tor nodes ---
de-anonymizing the users.
